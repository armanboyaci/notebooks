{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "\n",
    "There is a fair coin (one side heads, one side tails) and an unfair coin (both sides tails). You pick one at random, flip it 5 times, and observe that it comes up as tails all five times. What is the chance that you are flipping the unfair coin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling coins:\n",
    "\n",
    "**Sample space**: The possible outcomes of a coin toss.\n",
    "\n",
    "$\\mathcal{X} = \\{ \\text{heads}, \\text{tails} \\}$\n",
    "\n",
    "**Random variable**:\n",
    "\n",
    "A simple model over binary outcomes $\\{ 0, 1 \\}$ can be chosen as a Bernoulli distribution which is a discrete probability distribution.\n",
    "\n",
    "Let $X$ be a random variable denoting the outcome of a binary experiment,\n",
    "\n",
    "$X \\sim \\text{Ber}(p)$\n",
    "\n",
    "where $\\text{Ber}(p)$ denotes a Bernoulli distribution with parameter $p \\in (0,1)$. \n",
    "\n",
    "The probability mass function (pmf) is\n",
    "\n",
    "$p(X=0) = (1-p)$\n",
    "\n",
    "$p(X=1) = p$\n",
    "\n",
    "The pmf can be rewritten more concisely as\n",
    "\n",
    "$p(X=i) = p^{i} (1-p)^{(1-i)}, \\quad i \\in \\{ 0, 1 \\}$\n",
    "\n",
    "This can be used to model a coin toss using a simple mapping $\\mathbb{I} : \\mathcal{X} \\to \\{ 0, 1 \\}$ to the binary outcome space as \n",
    "\n",
    "$\\mathbb{I}(x) = i, \\quad x \\in \\mathcal{X}, \\quad i \\in \\{ 0, 1 \\}$ such that\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{I}(x) = \\begin{cases}\n",
    "        0, \\quad \\text{if} \\, x = \\text{heads} \\\\\n",
    "        1, \\quad \\text{if} \\, x = \\text{tails}\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "The parameter $p$ is the probability of seeing $\\text{tails}$.\n",
    "\n",
    "The pmf of a coin toss is then\n",
    "\n",
    "$p(X=x) = p^{\\mathbb{I}(x)} (1-p)^{(1-\\mathbb{I}(x))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a sequence of coin tosses:\n",
    "\n",
    "Let $\\{ X_n \\}_{n=1}^{N}$ be a sequence of independent coin tosses of length $N$. Then given a sequence of outcomes $\\{ x_n \\}_{n=1}^{N}$ the joint probability of all independent coin tosses $X_n$ is\n",
    "\n",
    "\\begin{align*}\n",
    "    p\\left( \\{ X_n = x_n \\}_{n=1}^{N} \\right) &= \\prod_{n=1}^{N} p^{\\mathbb{I}(x_n)} (1-p)^{(1-\\mathbb{I}(x_n))} \\\\\n",
    "    &= p^{ \\displaystyle \\left( \\sum_{n=1}^{N} \\mathbb{I}(x_n)  \\right)  } (1-p)^{ \\displaystyle \\left( \\sum_{n=1}^{N} \\left( 1 - \\mathbb{I}(x_n) \\right)  \\right)  } \\\\\n",
    "    &= p^{ \\displaystyle \\left( \\sum_{n=1}^{N} \\mathbb{I}(x_n)  \\right)  } (1-p)^{ \\displaystyle \\left( N -  \\sum_{n=1}^{N} \\mathbb{I}(x_n) \\right)   }\n",
    "\\end{align*}\n",
    "\n",
    "The joint probability mass function (pmf) is over the complete set of coin tosses $ \\{ X_n \\}_{n=1}^{N}$. Hence a sample from this distribution is an $N$-dimensional binary variable.\n",
    "\n",
    "Notice that the functional form of the joint probability mass function suggests a simpler parameterisation for this problem. If we are only interested in the total number of $\\text{heads}$ or $\\text{tails}$, we can define a new parameter $k$ such that\n",
    "\n",
    "\\begin{equation*}\n",
    "    k = \\sum_{n=1}^{N} \\mathbb{I}(x_n)\n",
    "\\end{equation*}\n",
    "\n",
    "Hence $k$ denotes the number of $\\text{tails}$ in $N$ repeated coin tosses.\n",
    "\n",
    "Let $Y$ be a random variable denoting the number of $\\text{tails}$ in $\\{ X_n \\}_{n=1}^{N}$\n",
    "\n",
    "\\begin{equation*}\n",
    "    Y = \\sum_{n=1}^{N} \\mathbb{I}(X_n)\n",
    "\\end{equation*}\n",
    "\n",
    "Note that this is different from the full joint distribution $p\\left( \\{ X_n = x_n \\}_{n=1}^{N} \\right)$.\n",
    "\n",
    "The sample space $\\mathcal{Y}$ of $Y$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathcal{Y} = \\{ 0, 1, 2, \\cdots, N \\}\n",
    "\\end{equation*}\n",
    "\n",
    "Instead of\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathcal{X}^{N} =  \\{ 0, 1 \\} \\times \\{ 0, 1 \\} \\times \\cdots \\times \\{ 0, 1 \\}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pmf of $Y$ can be derived in several steps that involve the summation of two independent random variables.\n",
    "\n",
    "Define an intermediate sequence of variables $\\{ Z_n \\}_{n=1}^{N}$ such that\n",
    "\n",
    "\\begin{align*}\n",
    "    Z_1 &= \\mathbb{I}(X_1) \\\\\n",
    "    Z_2 &= Z_1 + \\mathbb{I}(X_2) \\\\\n",
    "    &\\vdots \\\\\n",
    "    Z_N &= Z_{N-1} + \\mathbb{I}(X_N)\n",
    "\\end{align*}\n",
    "\n",
    "Hence $Y = Z_N$.\n",
    "\n",
    "At the start of the sequence, $Z_1 \\sim p(Z_1) = \\text{Ber}(p)$. For $Z_2$ the sample space $\\{ 0, 1 \\}$ is extended to $\\{ 0, 1, 2 \\}$ and the pmf can be expressed as a convolution as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Pr}(Z_2 = z) = \\sum_{j=0}^{1} \\text{Pr}(\\mathbb{I}(X_1) = j) \\text{Pr}(\\mathbb{I}(X_2) = z-j)\n",
    "\\end{align*}\n",
    "\n",
    "where the probability of values outside of the sample space are set to zero, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Pr}(\\mathbb{I}(X_2) = 2) &= 0 \\\\\n",
    "    \\text{Pr}(\\mathbb{I}(X_2) = -1) &= 0\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Then the probability of each outcome can be found as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Pr}(Z_2 = 0) &= \\text{Pr}(\\mathbb{I}(X_1) = 0) \\text{Pr}(\\mathbb{I}(X_2) = 0) \\\\ \n",
    "    &= (1-p)^{2}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Pr}(Z_2 = 1) &= \\text{Pr}(\\mathbb{I}(X_1) = 0) \\text{Pr}(\\mathbb{I}(X_2) = 1) +  \\text{Pr}(\\mathbb{I}(X_1) = 1) + \\text{Pr}(\\mathbb{I}(X_2) = 0) \\\\ \n",
    "    &= (1-p) p + p (1-p) \\\\\n",
    "    &= 2 p (1-p)\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{Pr}(Z_2 = 2) &= \\text{Pr}(\\mathbb{I}(X_1) = 1) \\text{Pr}(\\mathbb{I}(X_2) = 1) \\\\ \n",
    "    &= p^{2}\n",
    "\\end{align*}\n",
    "\n",
    "Recall the joint pmf $p(X_1, X_2)$ of two Bernoulli distributions $p(X_1=x_1) = p^{\\mathbb{I}(x_1)} (1-p)^{(1 - \\mathbb{I}(x_1))}$ and $p(X_2=x_2) = p^{\\mathbb{I}(x_2)} (1-p)^{(1 - \\mathbb{I}(x_2))}$ as\n",
    "\n",
    "\\begin{align*}\n",
    "    p(X_1, X_2) = p^{ \\displaystyle \\left( \\sum_{n=1}^{2} \\mathbb{I}(x_n)  \\right)  } (1-p)^{ \\displaystyle \\left( 2 -  \\sum_{n=1}^{2} \\mathbb{I}(x_n) \\right)   }\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Notice that since there are two possible events that may lead to $Z_2 = 1$, the corresponding probability mass is scaled by $2$. Hence $p(Z_2) \\neq p(X_1, X_2)$ but $p(Z_2) \\propto p(X_1, X_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required normalisation constant for the joint pmf $p(X_1, X_2)$ is a function that returns the number of possible cases that may result in the outcome $j \\in \\{ 0, 1, 2 \\}$. Hence it is the binomial coefficient, which denotes the number of ways that $k$ objects can be chosen among $N$ identical objects without accounting for to their order, as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\binom{N}{k} = \\frac{N!}{k! (N-k)!}\n",
    "\\end{align*}\n",
    "\n",
    "Hence the pmf of $Z_2$ can be found as\n",
    "\n",
    "\\begin{align*}\n",
    "    p(Z_2 = j) = \\binom{2}{j}  p^{  j  } (1-p)^{ \\left( 2 -  j \\right)   }\n",
    "\\end{align*}\n",
    "\n",
    "which is the Binomial distribution $\\text{B}(2; p)$.  \n",
    "\n",
    "This can be generalised to the full sequence such that $Y \\sim \\text{B}(N; p)$ as\n",
    "\n",
    "\\begin{align*}\n",
    "    p(Y = k) = \\binom{N}{k} p^{k} (1-p)^{(N-k)}\n",
    "\\end{align*}\n",
    "\n",
    "Note that this expression is valid for the case $N=1$ which corresponds to the Bernoulli distribution $\\text{Ber}(p) = \\text{B}(1; p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "For question 1, the coin is flipped for $5$ times. Therefore the likelihood model is a Binomial distribution $\\text{B}(5;p_{\\theta})$ such that where $p_{\\theta}$ is the probability of $\\text{tails}$ for a coin indexed by $\\theta \\in \\{ \\text{fair}, \\text{unfair} \\}$.\n",
    "\n",
    "\\begin{equation*}\n",
    "    p_{\\theta} = \\begin{cases}\n",
    "        0.5, \\quad \\text{if} \\,\\, \\theta = \\text{fair} \\\\\n",
    "        1.0, \\quad \\text{if} \\,\\, \\theta = \\text{unfair} \n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "If the coin is picked at random, this can be represented as a random variable $\\Theta \\sim p(\\theta) = \\text{Ber}(m=0.5)$ where $m$ is the probability of choosing $\\text{unfair}$.\n",
    "\n",
    "Given an observation of the number of times $k$ a coin produces $\\text{tails}$ in $5$ repeated flips, the distribution over the coins $p(\\theta)$ can be updated using Bayes' theorem as\n",
    "\n",
    "\\begin{equation*}\n",
    "    p(\\theta |Â k) = \\frac{ \\text{B}(5; k | \\theta) p(\\theta) }{\\sum_{\\theta} \\text{B}(5; k | \\theta) p(\\theta)}\n",
    "\\end{equation*}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{B}(5; k | \\text{fair}) p(\\text{fair}) &= \\binom{5}{k} (0.5)^{5}  (1-m) \\\\\n",
    "    \\text{B}(5; k | \\text{unfair}) p(\\text{unfair}) &= \\binom{5}{k} (1.0)^{k} m \n",
    "\\end{align*}\n",
    "\n",
    "We're given that $k=5$, hence\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{B}(5; 5 | \\text{fair}) p(\\text{fair}) &=  \\frac{(1-m)}{2^{5}}   \\\\\n",
    "    \\text{B}(5; 5 | \\text{unfair}) p(\\text{unfair}) &=  m \n",
    "\\end{align*}\n",
    "\n",
    "The posterior can be found as\n",
    "\n",
    "\\begin{align*}\n",
    "    p( \\text{fair} |Â k=5) &= \\frac{ \\frac{(1-m)}{2^{5}} }{ \\frac{(1-m)}{2^{5}} + m } \\\\\n",
    "    &= \\frac{ 1 }{ 1 + \\frac{2^5 m}{(1-m)} }\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    p( \\text{unfair} |Â k=5) &= \\frac{ m }{ \\frac{(1-m)}{2^{5}} + m } \\\\\n",
    "    &= \\frac{ 1 }{ 1 + \\frac{(1-m)}{2^5 m} }\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "def probability_unfair(m):\n",
    "    return 1 / (1 + ((1-m)/(2**5 * m)))\n",
    "\n",
    "print(probability_unfair(m=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalising to $N$ flips and coins with unknown parameters\n",
    "\n",
    "\\begin{align*}\n",
    "    p(k | N, \\theta) &= \\text{B}(N; k| \\theta_1) \\delta_{\\theta_1}(\\theta=\\theta_1) + \\text{B}(N; k| \\theta_2) \\delta_{\\theta_2}(\\theta=\\theta_2) \\\\\n",
    "    p(\\theta) &= p_{\\theta_1} \\delta_{\\theta_1}(\\theta = \\theta_1) + p_{\\theta_2} \\delta_{\\theta_2}(\\theta = \\theta_2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
